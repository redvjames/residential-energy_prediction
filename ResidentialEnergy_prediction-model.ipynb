{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60df9259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:26.835294Z",
     "start_time": "2023-06-19T14:26:26.826457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.\n",
       "js\"></script>\n",
       "<script>\n",
       "code_show=true;\n",
       "function code_toggle() {\n",
       "if (code_show){\n",
       "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').hide();\n",
       "} else {\n",
       "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').show();\n",
       "}\n",
       "code_show = !code_show\n",
       "}\n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" \n",
       "value=\"Click here to toggle on/off the raw code.\"></form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.\n",
    "js\"></script>\n",
    "<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').hide();\n",
    "} else {\n",
    "$('div.jp-CodeCell > div.jp-Cell-inputWrapper').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" \n",
    "value=\"Click here to toggle on/off the raw code.\"></form>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4906a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:26.843596Z",
     "start_time": "2023-06-19T14:26:26.837760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7cd4f3",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/Page_Title.png\" width=\"80%\" height=\"80%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb69886",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#FAA01D; color:#F5F5F1; padding: 10px;\">Introduction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f5a32d",
   "metadata": {},
   "source": [
    "Tired of blackboxes in time series deep learning models? This post will discuss a state-of-the-art, hot off-the-press forecasting model called NBEATSx or Neural Basis Expansion Analysis for Time Series with Exogenous Variables. We’ll apply this model in the residential energy consumption context, where we’ll explore how this new model incorporates explainability through time series decomposition and how its performance, in terms of mean absolute percentage error, compares to other existing time series models from basic (e.g., season naive) to more complex (e.g., Prophet)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6d374d",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Motivation</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3c7d7",
   "metadata": {},
   "source": [
    "Have you ever experienced bill shock when you received your monthly energy bill? It's common, especially for first-time renters or homeowners who are still familiar with their energy consumption and utility rates. Underestimating energy usage and rates can strain household budgets, causing stress and anxiety. That's where the power of information comes into play. By providing consumers with the tools to make informed decisions about their energy usage, we can empower individuals to take control of their consumption patterns. Whether through real-time monitoring, personalized energy-saving tips, or access to energy usage data, the goal is to arm consumers with the knowledge they need to optimize their energy usage and save money."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685213d",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Background of the Study</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446682bb",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Residential Energy Use-Case</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89087849",
   "metadata": {},
   "source": [
    "Residential energy consumption is the amount of energy households use for varied purposes, such as heating, cooling, lighting, and operating appliances and electronic devices. Energy is crucial for maintaining our daily comfort and convenience at home.\n",
    "\n",
    "However, residential consumers often face challenges when managing their energy usage and the associated costs. One common challenge is the phenomenon known as \"bill shock.\" Bill shock occurs when consumers receive their monthly energy bills with unexpectedly high charges. This is particularly true among first-time renters or homeowners who may underestimate their energy usage or be unaware of the utility rates. Consequently, the unanticipated energy cost increase adversely affects consumers' ability to plan and manage their expenses effectively. \n",
    "\n",
    "Consumers have turned to various solutions to alleviate the challenges of bill shock. Some rely on energy-tracking apps to monitor their usage. Still, these apps often require manual input of appliance information or the purchase of expensive smart devices. This manual input can be time-consuming and prone to errors, while the cost of smart devices may be prohibitive for some.\n",
    "\n",
    "As such, there is a growing need for an automated solution to effortlessly track energy use, predict monthly bills, and maintain a comprehensive record of past usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a442ae",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/Kardo.png\" width=\"60%\" height=\"60%\"></center>\n",
    "<center>Typical Residential Setup</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33a8dc",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Time Series Forecasting</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc4acc",
   "metadata": {},
   "source": [
    "Time series analysis opens up a world of possibilities for forecasting future values based on sequential data. Whether studying residential energy consumption over different time intervals like annual, monthly, daily, or even hourly readings, this analytical approach helps us delve into patterns, spot anomalies, and assess the impact of external factors. Common models like Autoregressive Integrated Moving Averages (ARIMA), Exponential Smoothing (ES), and Seasonal Decomposition of Time Series (STL) capture trends, dependencies, and seasonal patterns in energy usage. These models could help empower us homeowners and energy providers to optimize consumption, make informed decisions, and achieve cost savings.\n",
    "\n",
    "But what makes it even more exciting is the advent of state-of-the-art models that have revolutionized the accuracy of time series forecasting.\n",
    "\n",
    "Imagine a world where we can harness the power of deep neural networks to capture non-linear relationships within time series data. That's exactly what MLP-based models offer. By diving deep into the data, these models excel at forecasting short-term dependencies, providing valuable insights into the energy consumption trends of households.\n",
    "\n",
    "But what about long-term patterns? That's where Recurrent Neural Networks (RNNs) steal the show. By incorporating recurrent connections, RNNs can capture and retain crucial information, helping us understand the long-term dynamics of energy consumption. Variants like LSTM and GRU further enhance the model's ability to grasp the complexity of time series data.\n",
    "\n",
    "Now, let's talk about transformers. Originally designed for natural language processing, transformers have found their way into the realm of time series analysis. With their self-attention mechanisms, these models can uncover global dependencies, revealing the long-term patterns that influence energy consumption.\n",
    "\n",
    "But the innovations don't stop there. Temporal Convolutional Networks (TCNs) have emerged as a powerful player in time series analysis. These models leverage dilated convolutions to capture both short and long-range dependencies simultaneously. Their scalable and efficient architecture makes them an excellent choice for analyzing sequential data, such as energy consumption records.\n",
    "\n",
    "Ensemble methods add another layer of sophistication to time series modeling. By combining predictions from multiple models, we can harness the strengths of each approach and achieve enhanced forecasting accuracy. Techniques like stacking and boosting pave the way for more robust and reliable predictions.\n",
    "\n",
    "While the accuracy of these state-of-the-art models is impressive, there's another crucial aspect to consider: explainability. In the world of complex models, understanding and interpreting their inner workings becomes paramount. Explainability allows us to unravel the factors driving the predictions, uncover hidden relationships, and gain valuable insights. Regarding decision-making processes, this transparency instills confidence. It empowers stakeholders to make informed choices based on the forecasts generated by these advanced models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed36396",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/NBEATSx.png\" width=\"80%\" height=\"80%\"></center>\n",
    "<center>NBEATSx Architecture</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb587ef",
   "metadata": {},
   "source": [
    "Time series analysis has come a long way, thanks to the advancements in state-of-the-art models. These powerful tools have revolutionized forecasting accuracy, whether MLP-based models, RNNs, transformers, TCNs, or ensemble methods. Combining their strengths with explainability can unlock the true potential of time series data. Neural Basis Expansion Analysis with exogenous variables (NBEATSx), a groundbreaking architecture, comes in here. NBEATSx incorporates both deep learning and explainability. Recently published by Kin Olivares et al. in the International Journal of Forecasting, this model's beauty lies in its simplicity and effectiveness.[3] At its core is a fully connected layer, one of the simplest neural networks, updated through backcasting to remove learned patterns. The final forecast is obtained by summing up the partial forecasts of the model stacks. Notably, NBEATSx offers interpretability by performing time series decomposition to reveal trends and seasonality patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea64bd",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a17fb",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/Dataset.png\" width=\"70%\" height=\"70%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d00155",
   "metadata": {},
   "source": [
    "For our pilot study, as local Philippine data is unavailable, we will use a proxy dataset called the Hourly Usage of Energy (HUE) Dataset for Buildings in British Columbia. This dataset, provided by Simon Fraser University in Canada, covers the period from June 2012 to September 2015. It includes various features such as date, day, month, energy consumption in kilowatt-hours (kWh), hour of the day, humidity levels, holiday indicators, pressure readings, and temperatures. By analyzing this dataset, we aim to gain insights into energy consumption patterns and explore the effectiveness of different time series models in forecasting and optimizing energy usage. Although not specific to the Philippines, this dataset provides a valuable starting point for our pilot study. You can access the dataset here: https://www.nature.com/articles/s41597-022-01455-7 [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15657dc5",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#FAA01D; color:#F5F5F1; padding: 10px;\">Methodology</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c0af2",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/Methodology.png\" width=\"90%\" height=\"90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a03eda",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Setting Up</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d38fcf",
   "metadata": {},
   "source": [
    "Before everything, we must first install the necessary libraries. We used the following non-standard Python libraries\n",
    "\n",
    "* `tqdm`, `seaborn`, `scikit-learn`, `torch`, and `neuralforecast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9cc5cde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:26.850059Z",
     "start_time": "2023-06-19T14:26:26.846909Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install tqdm\n",
    "# pip install seaborn\n",
    "# pip install scikit-learn\n",
    "# pip install torch\n",
    "# pip install neuralforecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c5c13",
   "metadata": {},
   "source": [
    "After installing the non-standard Python libraries, let us import all necessary libraries.\n",
    "\n",
    "**Basic Imports:** `os`, `itertools`, `tqdm`, `numpy`, `pandas`, `matplotlib`, `seaborn`.\n",
    "\n",
    "**Deep Learning:** `sklearn`, `torch`, and `neuralforecast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16adb68d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:26.856082Z",
     "start_time": "2023-06-19T14:26:26.852484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quick fix for permission error\n",
    "import os\n",
    "os.environ['XDG_CACHE_HOME'] = '/home/msds2023/fgarcia/.cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a956a240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:31.603721Z",
     "start_time": "2023-06-19T14:26:26.858604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# NBEATSx imports\n",
    "from neuralforecast.models import NBEATSx\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "from neuralforecast.losses.pytorch import MAPE\n",
    "from sklearn.metrics import (mean_absolute_error,\n",
    "                             mean_absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382fb116",
   "metadata": {},
   "source": [
    "Let us also check if there is an available GPU for Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee99f2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:31.624956Z",
     "start_time": "2023-06-19T14:26:31.606450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Device is cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Your Device is {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579ee98",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Data Preprocessing</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21563e4f",
   "metadata": {},
   "source": [
    "The Hourly Usage of Energy (HUE) dataset comprises multiple csv files, including Residential 1-28, Solar, Weather WYJ, Weather YVR, and Holidays. However, we will only work with three CSV files for our specific analysis: holidays, weatherYVR, and residential_1.\n",
    "\n",
    "The holidays CSV file contains information about dates, days of the week, weekends, holidays, and daylight saving time (dst). The weather YVR CSV file includes data on dates, hours, temperature, humidity, pressure, and weather conditions. Lastly, the residential_1 CSV file details dates, hours, and energy consumption in kilowatt-hours (kWh)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19f21e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Energy Consumption</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17aa613",
   "metadata": {},
   "source": [
    "In this part of the post, we pre-processed the data from residential_1.csv which will be used as the basis of residential energy consumption in the succeeding sections. The following pre-processing were were conducted:\n",
    "\n",
    "1. *Converted the date column to datetime format.* This is to ensure that the dates are uniformly represented in the dataset. This allowed us to access a wide range of date-specific functionalities and operations, and enabled us to facilitate easy and efficient time-based indexing which is necessary in performing time series analysis.\n",
    "2. *Drop duplicates.* Dropping duplicates allowed us to preserve the integrity of the dataset by ensuring that each data point is a unique and distinct observation. This also helped us avoid any bias and removed any unnecessary consumption of storage space. \n",
    "3. *Remove the first day.* Due to incomplete data, where the first day's data point started at 1 AM instead of 12 midnight, we made the decision to exclude the first data point.\n",
    "4. *Set datetime to index*. Since we did step 1, we can now set the datetime column to index which can allow us to take advantage of varied built-in time-series models in python (e.g Pandas).\n",
    "5. *Fill in missing dates and backfill to impute.* We did this to ensure continuity in data and each data point is evenly spaced. The method we used to impute the values is backfill.\n",
    "6. *Resample to day.* In this step we resampled the hourly data to a daily perspective for our time-series analysis. This allowed us to aggregate the energy consumption data at a daily level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b245dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:31.648156Z",
     "start_time": "2023-06-19T14:26:31.627133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('Residential_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffada106",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:31.866531Z",
     "start_time": "2023-06-19T14:26:31.650556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df_data = df.copy()\n",
    "\n",
    "# Convert the date column to datetime format\n",
    "df_data['date'] = pd.to_datetime(df_data['date'])\n",
    "\n",
    "# Create the datetime column by adding the hour to the date\n",
    "df_data['datetime'] = df_data['date'] + pd.to_timedelta(df_data['hour'],\n",
    "                                                        unit='H')\n",
    "df_data = df_data.drop(columns=['date', 'hour'])\n",
    "\n",
    "# Drop duplicates\n",
    "df_data = df_data.drop_duplicates(subset='datetime')\n",
    "df_data = df_data.sort_values(by='datetime')\n",
    "\n",
    "# Remove the first day and last day (not complete)\n",
    "df_data = df_data[23:-1]\n",
    "\n",
    "# Set datetime to index\n",
    "df_data = df_data.set_index('datetime')\n",
    "df_data.index = pd.to_datetime(df_data.index)\n",
    "\n",
    "# Fill in missing dates\n",
    "datetime_range = pd.date_range(start='2012-06-02 00:00:00',\n",
    "                               end='2015-10-02 23:00:00', freq='H')\n",
    "df_date = pd.DataFrame(index=datetime_range)\n",
    "df_comp = df_date.merge(df_data, how='outer',\n",
    "                        left_index=True, right_index=True)\n",
    "\n",
    "# Backfill to impute\n",
    "df_energy = df_comp.fillna(method='bfill')\n",
    "\n",
    "# Resample to day\n",
    "df_day = df_energy[['energy_kWh']].resample('D').sum()[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7db906",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Exogeneous Variables</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dc102",
   "metadata": {},
   "source": [
    "As mentioned above, we used the Weather_YVR.csv and Holiday.csv as our exogenous variables.\n",
    "\n",
    "For the Weather_YVR.csv, we only used the  date, hour, temperature, humidity, and pressure features. We conducted the following pre-processing steps:\n",
    "\n",
    "1. *Clean up the datetime column.* In this part of the code, we cleaned up and transformed the date and hour columns into a single datetime column in the dataframe *df_exo*.\n",
    "2. *Drop duplicates.* We dropped any duplicate rows based on the 'datetime' column in the dataframe df_exo and sorted the dataframe in chronological order.\n",
    "3. *Set datetime to index.* This step allowed us to access and process the data using built-in time-series models in python. \n",
    "4. *Resample to day.* We did this to ensure continuity in data and each data point is evenly spaced. The method we used to impute the values is backfill. \n",
    "5. *Add more feature to capture long term seasonality.* This step is crucial as it allowed us to incorporate long-term seasonality into the analysis, the 'dayofweek' and 'month' features are added to the 'df_exo' dataframe. These features captured the day of the week (0-6, where Monday is 0 and Sunday is 6) and the month (1-12) respectively, based on the index values of the dataframe.\n",
    "6. *Dataframe containing both consumption and exogeneous.* This is the step where we merged the above previous dataframe with the current dataframe. The resulting dataframe, df_all, contains both the energy consumption data and the exogenous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e96a0903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:31.961072Z",
     "start_time": "2023-06-19T14:26:31.870504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_exo = pd.read_csv('Weather_YVR.csv',\n",
    "                     usecols=['date', 'hour', 'temperature',\n",
    "                              'humidity', 'pressure'])\n",
    "\n",
    "# Clean up datetime\n",
    "df_exo['date'] = pd.to_datetime(df_exo['date'])\n",
    "df_exo['datetime'] = df_exo['date'] + pd.to_timedelta(df_exo['hour'],\n",
    "                                                      unit='H')\n",
    "df_exo = df_exo.drop(columns=['date', 'hour'])\n",
    "\n",
    "# Drop duplicates\n",
    "df_exo = df_exo.drop_duplicates(subset='datetime')\n",
    "df_exo = df_exo.sort_values(by='datetime')\n",
    "\n",
    "# Set datetime to index\n",
    "df_exo = df_exo.set_index('datetime')\n",
    "df_exo.index = pd.to_datetime(df_exo.index)\n",
    "\n",
    "# Resample to day\n",
    "df_exo = df_exo[['temperature', 'humidity', 'pressure']].resample('D').mean()\n",
    "\n",
    "# Add more feature to capture long term seasonality\n",
    "df_exo['dayofweek'] = df_exo.index.dayofweek\n",
    "df_exo['month'] = df_exo.index.month\n",
    "\n",
    "# Dataframe containing both consumption and exogeneous\n",
    "df_all = df_exo.merge(df_day, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477056fb",
   "metadata": {},
   "source": [
    "For the Holiday.csv we only used the date and holiday columns as our features. We didn’t merge this with df_all as we used this for the Prophet time-series model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97cde845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:31.972514Z",
     "start_time": "2023-06-19T14:26:31.962732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load holiday exogeneous variable\n",
    "df_holiday = pd.read_csv('Holidays.csv', usecols=['date', 'holiday'])\n",
    "df_holiday['ds'] = pd.to_datetime(df_holiday['date'])\n",
    "df_holiday = df_holiday.dropna().drop(columns='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e35c1",
   "metadata": {},
   "source": [
    "The final part Dataframe for NBEATSx is based on the specific format that NBEATSx accepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f55aca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:32.063316Z",
     "start_time": "2023-06-19T14:26:31.974123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataframe for NBEATSx\n",
    "df_beats = df_all.copy()\n",
    "df_beats['unique_id'] = 1\n",
    "df_beats = df_beats.reset_index()\n",
    "df_beats = df_beats.rename(columns={'energy_kWh': 'y', 'index': 'ds'})\n",
    "df_beats = df_beats.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae9e16f",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Exploratory Data Analysis</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347d81d",
   "metadata": {},
   "source": [
    "In our analysis, we utilized time series plots to examine the overall trend of energy consumption in British Columbia from June 2012 to September 2015. The first plot focused on daily energy consumption, providing insights into trend and seasonality. The second plot incorporated exogenous variables (temperature, humidity, and atmospheric pressure) alongside energy consumption to explore their relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a9466",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Energy Consumption Time Series Plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ba823e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:32.400854Z",
     "start_time": "2023-06-19T14:26:32.067640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Daily_Time_Series.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_hday = (df_holiday.merge(df_day.reset_index(),\n",
    "                            how='left',\n",
    "                            left_on='ds',\n",
    "                            right_on='index')\n",
    "           [['ds', 'energy_kWh']]\n",
    "           .dropna())\n",
    "\n",
    "datetime_range_eda = pd.date_range(start='2012-06-02 00:00:00',\n",
    "                                   end='2015-10-02 23:00:00',\n",
    "                                   periods=11)\n",
    "\n",
    "# Plot whole dataset\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "sns.lineplot(data=df_day, y=df_day.energy_kWh, x=df_day.index,\n",
    "             color='orange', legend=None)\n",
    "plt.xticks(datetime_range_eda)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "\n",
    "# Plot\n",
    "plt.ylabel(\"Energy(kWh)\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.title('Daily Time Series Plot of Energy Consumption',\n",
    "          fontsize=20, pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Daily_Time_Series.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Daily_Time_Series.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:100%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6a2a7",
   "metadata": {},
   "source": [
    "In the plot above, we can see that energy consumption increases each year in the middle of October and decreases by the end of February. The energy in the months with high consumption typically ranges from 30 to 36kWh per day, but the consumption could still go up to 41 to 47kWh. While in the months with low consumption, the energy typically ranges from 20 to 25 kWh per day. Below we could explore further why this might be the case. But it is important to keep in mind that this dataset is taken from British Columbia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ef5d9",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Exogeneous Variables Time Series Plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a43932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:26:32.703518Z",
     "start_time": "2023-06-19T14:26:32.402591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Exo_Time_Series.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:100%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot exogeneous variable\n",
    "df_eda = df_all[:'2015-08-31'].reset_index()\n",
    "df_eda['year'] = pd.DatetimeIndex(df_eda['index']).year\n",
    "df_line = (df_eda.groupby(['year', 'month'])['temperature', 'humidity',\n",
    "                                             'pressure', 'energy_kWh']\n",
    "           .mean().reset_index())\n",
    "df_line['date'] = pd.to_datetime(df_line[['year', 'month']].assign(DAY=1))\n",
    "df_line2 = df_line.drop(columns=['year', 'month'])\n",
    "\n",
    "datetime_range_eda = pd.date_range(start='2012-06-02 00:00:00',\n",
    "                                   end='2015-10-02 23:00:00',\n",
    "                                   periods=11)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "sns.lineplot(x='date', y='value', hue='variable',\n",
    "             data=pd.melt(df_line2, 'date'),\n",
    "             palette='rocket', legend=None)\n",
    "\n",
    "plt.ylabel(\"Value\")\n",
    "plt.xlabel(\"Month-Year\")\n",
    "plt.title('Time Series Plot of Energy Consumption and Exogenous Variables',\n",
    "          fontsize=20, pad=20)\n",
    "ax.text(pd.Timestamp(\"2015-06-25\"), 10, 'Temperature(°C)', color='#321854')\n",
    "ax.text(pd.Timestamp(\"2015-06-25\"), 32, 'Energy(kWh)', color='#cc5f16')\n",
    "ax.text(pd.Timestamp(\"2015-06-25\"), 65, 'Humidity(%)', color='#a81b64')\n",
    "ax.text(pd.Timestamp(\"2015-06-25\"), 95, 'Pressure(kPa)', color='red')\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "plt.xticks(datetime_range_eda)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Exo_Time_Series.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Exo_Time_Series.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:100%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3187830",
   "metadata": {},
   "source": [
    "In the plot above, first, let's focus on the relationship between energy consumption `Energy(kWh)` and `Temperature`. Same with the previous plot, we can see that starting from the middle of October, energy consumption starts to increase, and during this time, temperature decreases. On the other hand, starting from March, energy consumption decreases and temperature increases. This could be attributed to the dataset being based on British Columbia, where there are four seasons. \n",
    "\n",
    "Based on the illustration below, we could say that temperature decreases during the latter months of the Fall and continues until the end of the Winter season. Then temperature increases at the start of the Summer and continues until the Spring or early Fall seasons. This means that during the months with low temperatures, people consume more Energy because of their use of heaters to fight against the cold weather. It follows that during the months with high temperatures, they consume less Energy because of less use of their heaters due to the hotter weather.\n",
    "\n",
    "Looking at `Humidity`, we see it follows the `Energy(kWh)` trend. However, it is misleading to think that high humidity directly affects energy consumption. It is more proper to relate humidity and temperature, which are inversely related. This means that the relative humidity is higher if the air is cooler or if the temperature is lower.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457e7426",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/Seasons.png\" width=\"70%\" height=\"70%\"></center>\n",
    "<center>Seasons in British Columbia, Canda</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fc95b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Time Series Forecasting (NBEATSx)</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6459a",
   "metadata": {},
   "source": [
    "We predict the energy consumption of Kardo by showcasing the state-of-the-art forecasting model, NBEATSx. To fully utilize the model's capability, we aggregated the daily energy consumption with the exogenous variables collected. The forecasting will be done in 7-day (week) and 30-day (month) ahead forecasts to cover both short-term and long-term areas. To evaluate the model's effectiveness in predicting energy consumption, the results of NBEATSx will be compared to Seasonal Naive, which will serve as the baseline model. The evaluation metric is set to Mean Absolute Percentage Error (MAPE) to easily contextualize the magnitude of the scores when compared with other scores. Lastly, the models below are already hypertuned to produce the optimal MAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b5ccc",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Short-Term (7-day ahead) Forecast</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891cc5e",
   "metadata": {},
   "source": [
    "Before proceeding with the model, we must split the dataset into train and test splits. This is the accuracy of the models for data that it has not learned yet. We set the test set to be the last 7 days of the dataset's time period for this short-term forecast.\n",
    "\n",
    "Next, we train the model using the train set and iterate the training process in 1000 epochs. We optimize the following parameters to get the lowest MAPE:\n",
    "\n",
    "- input size, which is the size of the autoregressive input where the backcast is based\n",
    "- futr_exog_list, which is the list of future known variables\n",
    "- scaler_type, which is the type of scaler for temporal inputs normalization\n",
    "- n_harmonics sets the number of harmonic oscillations factored in the seasonality stack\n",
    "- n_polynomials set the degree of the trend stack\n",
    "- stack_types indicates which stacks the model will use\n",
    "- activation sets the activation function used in the neural network\n",
    "- learning_rate indicates how much the weights will change per iteration\n",
    "- mlp_units indicates the structure of hidden layers for each stack type\n",
    "- num_lr_decays indicates the number of times the learning rate is decayed or reduced in the training\n",
    "\n",
    "The random_seed is set so we can reproduce the results. Then, we use the model on the test set to evaluate how well the model performs on the energy consumption dataset and look at the MAPE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be33113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:00.252921Z",
     "start_time": "2023-06-19T14:26:32.705593Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 630\n",
      "2023-06-19 14:26:33.547963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-19 14:26:33.636288: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836c797972cd4282a048181969673ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792bab98914447e2b2e1a3c922ae11f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set forecast horizon\n",
    "hor_7 = 7\n",
    "\n",
    "# Splitting the dataset\n",
    "df_beats_train_7 = df_beats[:-hor_7]\n",
    "df_beats_test_7 = df_beats.iloc[-hor_7:].drop(columns='y')\n",
    "\n",
    "# 7 day-ahead forecast\n",
    "models = [NBEATSx(h=hor_7,\n",
    "                  input_size=(4*hor_7),\n",
    "                  max_steps=1000,\n",
    "                  futr_exog_list=['temperature', 'humidity',\n",
    "                                  'pressure', 'dayofweek', 'month'],\n",
    "                  scaler_type='robust',\n",
    "                  n_harmonics=3,\n",
    "                  n_polynomials=3,\n",
    "                  stack_types=['identity', 'trend', 'seasonality'],\n",
    "                  activation='LeakyReLU',\n",
    "                  loss=MAPE(),\n",
    "                  learning_rate=1e-4,\n",
    "                  mlp_units=3*[[256, 256]],\n",
    "                  num_lr_decays=1,\n",
    "                  random_seed=630\n",
    "                  )]\n",
    "nf = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "# Train & Predict\n",
    "nf.fit(df=df_beats_train_7)\n",
    "y_pred_df = nf.predict(futr_df=df_beats_test_7)\n",
    "\n",
    "# Save to dataframe\n",
    "df_nbtx_res_7 = y_pred_df.set_index('ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c7ba2",
   "metadata": {},
   "source": [
    "For the baseline model, Seasonal Naive, we use the previous week's energy consumption as the forecast for the succeeding week. Then we project the results as a dataframe, bar graph, and trend line showing the true values with the prediction of the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77f1730b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:00.282296Z",
     "start_time": "2023-06-19T14:27:00.255636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seasonal_Naive</td>\n",
       "      <td>3.041286</td>\n",
       "      <td>0.112502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBEATSx</td>\n",
       "      <td>1.247066</td>\n",
       "      <td>0.045908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model       MAE      MAPE\n",
       "0  Seasonal_Naive  3.041286  0.112502\n",
       "1         NBEATSx  1.247066  0.045908"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline\n",
    "df_snaive_7 = df_day.copy()\n",
    "df_snaive_7['Seasonal_Naive'] = df_day[['energy_kWh']].shift(hor_7)\n",
    "df_snaive_7 = df_snaive_7[['Seasonal_Naive']].iloc[-hor_7:]\n",
    "\n",
    "# Combine all predictions and actual\n",
    "df_predict_7 = df_day.copy()\n",
    "df_predict_7 = df_predict_7.rename(columns={'energy_kWh': 'Actual'})\n",
    "df_predict_7 = df_predict_7[-hor_7:]\n",
    "df_predict_7 = pd.concat([df_predict_7, df_snaive_7, df_nbtx_res_7], axis=1)\n",
    "\n",
    "# Append the model score to the results dataframe\n",
    "model_ls = []\n",
    "mae_ls = []\n",
    "mape_ls = []\n",
    "for col in df_predict_7.columns[1:]:\n",
    "    model_ls.append(col)\n",
    "    mae_ls.append(mean_absolute_error(df_predict_7['Actual'],\n",
    "                                      df_predict_7[col]))\n",
    "    mape_ls.append(mean_absolute_percentage_error(df_predict_7['Actual'],\n",
    "                                                  df_predict_7[col]))\n",
    "\n",
    "df_results_7 = pd.DataFrame(\n",
    "    {'Model': model_ls, 'MAE': mae_ls, 'MAPE': mape_ls})\n",
    "display(df_results_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea6bcaa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:00.403495Z",
     "start_time": "2023-06-19T14:27:00.284392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Short_MAPE_1.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:60%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Results of Different Models\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.barh(df_results_7['Model'], df_results_7['MAPE'], color='#FAA01D')\n",
    "ax.set_title('MAPE Comparison of Seasonal Naive and NBEATSx')\n",
    "ax.set_xlabel('Mean Absolute Percentage Error')\n",
    "ax.set_yticklabels(['Seasonal Naive', 'NBEATSx'])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Short_MAPE_1.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Short_MAPE_1.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:60%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db937a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:00.656691Z",
     "start_time": "2023-06-19T14:27:00.405485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Short_Prediction_1.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time Series Prediction\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(df_predict_7.index, df_predict_7['Actual'],\n",
    "        label='Actual', color='cornflowerblue', linewidth=3)\n",
    "ax.plot(df_predict_7.index, df_predict_7['Seasonal_Naive'],\n",
    "        label='Seasonal Naive', linestyle='--', color='indianred', linewidth=3)\n",
    "ax.plot(df_predict_7.index, df_predict_7['NBEATSx'],\n",
    "        label='NBEATSx', linestyle='--', color='#FAA01D', linewidth=3)\n",
    "ax.set_title('Actual vs. Seasonal Naive & NBEATSx Short-Term Prediction')\n",
    "ax.set_ylabel('Daily Energy Consumption (kWh)')\n",
    "ax.set_xlabel('Test Prediction Dates')\n",
    "ax.legend()\n",
    "ax.set_ylim(20, 35)\n",
    "ax.tick_params(axis='x', rotation=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Short_Prediction_1.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Short_Prediction_1.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d843013",
   "metadata": {},
   "source": [
    "Looking at the results of the 7-day ahead forecast, NBEATSx beats out Seasonal Naive by far (4.6% to 11.3%). The visualization of the predictions and the actual value shows that NBEATSx could follow the trend of the actual energy consumption (although the trend changes are minimal in the model) compared to the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56539205",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Long-Term (30-day ahead) Forecast</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add53823",
   "metadata": {},
   "source": [
    "The long-term forecast for energy consumption has almost the same flow as the short-term forecast. There are only two differences in the method: the forecast horizon, which is set to 30, and the hypertuned parameters of the models. The updated parameters for the month-ahead forecast are the following:\n",
    "- input_size set to a longer period to factor in the longer time horizon\n",
    "- n_harmonics and n_polynomials since the trend and seasonality are changed\n",
    "- learning_rate set to a smaller scale due to different granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0458a357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:00.684310Z",
     "start_time": "2023-06-19T14:27:00.658723Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 630\n"
     ]
    }
   ],
   "source": [
    "# Set forecast horizon\n",
    "hor_30 = 30\n",
    "\n",
    "# Splitting the dataset\n",
    "df_beats_train_30 = df_beats[:-hor_30]\n",
    "df_beats_test_30 = df_beats.iloc[-hor_30:].drop(columns='y')\n",
    "\n",
    "# 30 day-ahead forecast\n",
    "models = [NBEATSx(h=hor_30,\n",
    "                  input_size=135,  # 7-day lookback\n",
    "                  max_steps=1000,\n",
    "                  futr_exog_list=['temperature', 'humidity',\n",
    "                                  'pressure', 'dayofweek', 'month'],\n",
    "                  scaler_type='robust',\n",
    "                  n_harmonics=2,\n",
    "                  n_polynomials=1,\n",
    "                  stack_types=['identity', 'trend', 'seasonality'],\n",
    "                  activation='LeakyReLU',\n",
    "                  loss=MAPE(),\n",
    "                  learning_rate=1e-5,\n",
    "                  mlp_units=3*[[256, 256]],\n",
    "                  num_lr_decays=1,\n",
    "                  random_seed=630\n",
    "                  )]\n",
    "nf = NeuralForecast(models=models, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "707f1173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:25.947880Z",
     "start_time": "2023-06-19T14:27:00.686718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c97d2194584c4c867c02c0de5587c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d729d000018498e82ae87a7d4fdef51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train & Predict\n",
    "nf.fit(df=df_beats_train_30)\n",
    "y_pred_df = nf.predict(futr_df=df_beats_test_30)\n",
    "\n",
    "# Save to dataframe\n",
    "df_nbtx_res_30 = y_pred_df.set_index('ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a31a70c",
   "metadata": {},
   "source": [
    "The baseline model is set to the previous month's energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17192649",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:25.957648Z",
     "start_time": "2023-06-19T14:27:25.950457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline\n",
    "df_snaive_30 = df_day.copy()\n",
    "df_snaive_30['Seasonal_Naive'] = df_day[['energy_kWh']].shift(hor_30)\n",
    "df_snaive_30 = df_snaive_30[['Seasonal_Naive']].iloc[-hor_30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12eb0612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:25.975788Z",
     "start_time": "2023-06-19T14:27:25.959679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seasonal_Naive</td>\n",
       "      <td>4.499367</td>\n",
       "      <td>0.159477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBEATSx</td>\n",
       "      <td>2.562424</td>\n",
       "      <td>0.088149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model       MAE      MAPE\n",
       "0  Seasonal_Naive  4.499367  0.159477\n",
       "1         NBEATSx  2.562424  0.088149"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine all predictions and actual\n",
    "df_predict_30 = df_day.copy()\n",
    "df_predict_30 = df_predict_30.rename(columns={'energy_kWh': 'Actual'})\n",
    "df_predict_30 = df_predict_30[-hor_30:]\n",
    "df_predict_30 = pd.concat(\n",
    "    [df_predict_30, df_snaive_30, df_nbtx_res_30], axis=1)\n",
    "\n",
    "# Append the model score to the results dataframe\n",
    "model_ls = []\n",
    "mae_ls = []\n",
    "mape_ls = []\n",
    "for col in df_predict_30.columns[1:]:\n",
    "    model_ls.append(col)\n",
    "    mae_ls.append(mean_absolute_error(df_predict_30['Actual'],\n",
    "                                      df_predict_30[col]))\n",
    "    mape_ls.append(mean_absolute_percentage_error(df_predict_30['Actual'],\n",
    "                                                  df_predict_30[col]))\n",
    "\n",
    "df_results_30 = pd.DataFrame(\n",
    "    {'Model': model_ls, 'MAE': mae_ls, 'MAPE': mape_ls})\n",
    "display(df_results_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "442589e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:26.163674Z",
     "start_time": "2023-06-19T14:27:25.977680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Long_MAPE_1.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:60%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Results of Different Models\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.barh(df_results_30['Model'], df_results_30['MAPE'], color='#FAA01D')\n",
    "ax.set_title('MAPE Comparison of Seasonal Naive and NBEATSx')\n",
    "ax.set_xlabel('Mean Absolute Percentage Error')\n",
    "ax.set_yticklabels(['Seasonal Naive', 'NBEATSx'])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Long_MAPE_1.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Long_MAPE_1.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:60%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e2be50e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:26.430003Z",
     "start_time": "2023-06-19T14:27:26.165788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Long_Prediction_1.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time Series Prediction\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(df_predict_30.index, df_predict_30['Actual'],\n",
    "        label='Actual', color='cornflowerblue', linewidth=3)\n",
    "ax.plot(df_predict_30.index, df_predict_30['Seasonal_Naive'],\n",
    "        label='Seasonal Naive', linestyle='--', color='indianred',\n",
    "        linewidth=3)\n",
    "ax.plot(df_predict_30.index, df_predict_30['NBEATSx'],\n",
    "        label='NBEATSx', linestyle='--', color='#FAA01D', linewidth=3)\n",
    "ax.set_title('Actual vs. Seasonal Naive & NBEATSx Long-Term Prediction')\n",
    "ax.set_ylabel('Daily Energy Consumption (kWh)')\n",
    "ax.set_xlabel('Test Prediction Dates')\n",
    "ax.legend()\n",
    "ax.set_ylim(5, 40)\n",
    "ax.tick_params(axis='x', rotation=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Long_Prediction_1.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Long_Prediction_1.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47c126",
   "metadata": {},
   "source": [
    "The results of the 30-day ahead forecast show NBEATSx having a better MAPE than Seasonal Naive (8.8% vs 15.9%). It is expected to have a higher MAPE for the month ahead forecast since we forecast longer time horizons, leading to less accuracy. Another note is that the trend is no longer correctly captured in NBEATSx compared to the 7-day ahead forecast. Nonetheless, the model could predict energy consumption with lower MAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd2f91b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">XAI (Time Series Decomposition)</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce9f58d",
   "metadata": {},
   "source": [
    "One of the features of NBEATSx is its built-in explainability feature. The time series model can be decomposed according to the stacks set in the parameters. These stacks can be the trend, seasonality, and exogenous stacks. NBEATSx computes a level prediction that is the same throughout the forecast horizon, then adds the outputs of the different stacks for each forecast. The outputs of each stack will then be the explainability of the model as a decompose function is available to pull out all the outputs of each stack. This way, we can visualize how each forecast is affected by the trend, seasonality, and exogenous variables.\n",
    "\n",
    "However, one current limitation of the NBEATSx is that the exogenous stack is unavailable when the time series is decomposed. Only the trend and seasonality stacks are available and will be shown in this post. This results in an altered version of the forecasting model as exogenous variables are left, and the mlp_units will be updated to only the two stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6f43463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:26.446417Z",
     "start_time": "2023-06-19T14:27:26.432150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012-06-02</td>\n",
       "      <td>20.331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-06-03</td>\n",
       "      <td>22.844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-06-04</td>\n",
       "      <td>25.610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-06-05</td>\n",
       "      <td>24.127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-06-06</td>\n",
       "      <td>27.718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1211</td>\n",
       "      <td>2015-09-26</td>\n",
       "      <td>31.067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>1212</td>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>29.411</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>1213</td>\n",
       "      <td>2015-09-28</td>\n",
       "      <td>26.998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1214</td>\n",
       "      <td>2015-09-29</td>\n",
       "      <td>26.975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1215</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>23.496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         ds       y  unique_id\n",
       "0         0 2012-06-02  20.331          1\n",
       "1         1 2012-06-03  22.844          1\n",
       "2         2 2012-06-04  25.610          1\n",
       "3         3 2012-06-05  24.127          1\n",
       "4         4 2012-06-06  27.718          1\n",
       "...     ...        ...     ...        ...\n",
       "1211   1211 2015-09-26  31.067          1\n",
       "1212   1212 2015-09-27  29.411          1\n",
       "1213   1213 2015-09-28  26.998          1\n",
       "1214   1214 2015-09-29  26.975          1\n",
       "1215   1215 2015-09-30  23.496          1\n",
       "\n",
       "[1216 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataframe for NBEATSx time decomposition\n",
    "df_beatsxai = df_day.reset_index()\n",
    "df_beatsxai = df_beatsxai.rename(columns={'index': 'ds', 'energy_kWh': 'y'})\n",
    "df_beatsxai['unique_id'] = 1\n",
    "df_beatsxai = df_beatsxai.reset_index()\n",
    "display(df_beatsxai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78c140",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Short-Term Time Series Decomposition</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97031212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:44.657751Z",
     "start_time": "2023-06-19T14:27:26.450196Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8246c3b69fc74bc9894ca6339432f015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60d24aa7583450bb804357a104f28a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7 day-ahead daily forecast\n",
    "horizon = 7\n",
    "models = [NBEATSx(h=horizon,\n",
    "                  input_size=(4*horizon),  # 7-day lookback\n",
    "                  max_steps=1000,\n",
    "                  n_harmonics=2,\n",
    "                  n_polynomials=3,\n",
    "                  stack_types=['trend', 'seasonality'],\n",
    "                  activation='LeakyReLU',\n",
    "                  loss=MAPE(),\n",
    "                  learning_rate=1e-5,\n",
    "                  mlp_units=2*[[256, 256]],\n",
    "                  num_lr_decays=1,\n",
    "                  random_seed=630\n",
    "                  )]\n",
    "nf = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "nf.fit(df=df_beats_train_7)\n",
    "y_pred_df = nf.predict(futr_df=df_beats_test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "146b2e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:44.784261Z",
     "start_time": "2023-06-19T14:27:44.660116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce54352025d448aa993cc751e15c1a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NBEATSx decomposition plot\n",
    "model = nf.models[0]\n",
    "dataset, *_ = TimeSeriesDataset.from_df(df=df_beatsxai)\n",
    "y_hat = model.decompose(dataset=dataset, random_seed=630)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dc9730",
   "metadata": {},
   "source": [
    "The output of the decompose function results in a 1 x 3 x n matrix where n is the forecast horizon. The size of three corresponds to the level or baseline stack, trend, and seasonality in that order. Adding the outputs of the three stacks should result in the prediction output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9836792d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:27:45.274571Z",
     "start_time": "2023-06-19T14:27:44.791295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Short_Decomp.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:70%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "ax[0].plot(df_day[-hor_7:].values, label='Actual',\n",
    "           color='cornflowerblue', linewidth=3)\n",
    "ax[0].plot(y_hat.sum(axis=1).flatten(), label='Forecast',\n",
    "           color=\"#FAA01D\", linestyle='--', linewidth=3)\n",
    "ax[0].set_title('Actual vs. Forecast')\n",
    "ax[0].set_ylabel('Energy Consumption (kWh)')\n",
    "ax[0].legend()\n",
    "\n",
    "# Trend\n",
    "ax[1].plot(y_hat[0, 1]+y_hat[0, 0], color=\"#FAA01D\", linewidth=3)\n",
    "ax[1].set_title('Trend Decomposition')\n",
    "ax[1].set_ylabel('Energy Consumption (kWh)')\n",
    "\n",
    "# Seasonality\n",
    "ax[2].plot(y_hat[0, 2], color=\"#FAA01D\", linewidth=3)\n",
    "ax[2].set_title('Seasonality Decomposition')\n",
    "ax[2].set_ylabel('Energy Consumption (kWh)')\n",
    "ax[2].set_xlabel('Day of the Week')\n",
    "custom_labels = [0, 'Thu', 'Fri', 'Sat', 'Sun', 'Mon', 'Tue', 'Wed']\n",
    "ax[2].set_xticklabels(custom_labels)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Short_Decomp.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Short_Decomp.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:70%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7e119",
   "metadata": {},
   "source": [
    "Looking at the explainability of the 7-day ahead forecast, the trend increases exponentially from Thursday to Wednesday. This suggests the increasing trend of energy consumption of Kardo as days go by. The seasonality plot indicates that the Kardo has peak consumption on Saturdays and floor consumption on Thursdays.\n",
    "\n",
    "Note that we added the baseline prediction with the trend to show that adding the trend and seasonality will result in the prediction (since the level prediction is just a horizontal line when plotted)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aec316",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Long-Term Time Series Decomposition</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9eb8c",
   "metadata": {},
   "source": [
    "The month-ahead forecast has the flow as the week-ahead forecast with only the forecast horizon and some parameters being updated to adjust with the longer forecast horizon. The outputs will also be the same, where the trend and seasonality are the basis for explainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b681910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:03.511663Z",
     "start_time": "2023-06-19T14:27:45.276824Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f72809d9334507a84178c3a6353b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79277a6b5094883881a624897a263bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 30 day-ahead daily forecast\n",
    "models = [NBEATSx(h=hor_30,\n",
    "                  input_size=(4*hor_30),\n",
    "                  max_steps=1000,\n",
    "                  n_harmonics=2,\n",
    "                  n_polynomials=4,\n",
    "                  stack_types=['trend', 'seasonality'],\n",
    "                  activation='LeakyReLU',\n",
    "                  loss=MAPE(),\n",
    "                  learning_rate=1e-5,\n",
    "                  mlp_units=2*[[256, 256]],\n",
    "                  num_lr_decays=1,\n",
    "                  random_seed=630\n",
    "                  )]\n",
    "nf = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "# Train & Predict\n",
    "nf.fit(df=df_beats_train_30)\n",
    "y_pred_df = nf.predict(futr_df=df_beats_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a962fc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:03.636008Z",
     "start_time": "2023-06-19T14:28:03.516309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32ead5403234d9ca3b4c872f9e22f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NBEATSx decomposition plot\n",
    "model = nf.models[0]\n",
    "dataset, *_ = TimeSeriesDataset.from_df(df=df_beatsxai)\n",
    "y_hat = model.decompose(dataset=dataset, random_seed=630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e730142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:04.551069Z",
     "start_time": "2023-06-19T14:28:03.638282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Long_Decomp.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:70%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "ax[0].plot(df_day[-hor_30:].values, label='Actual',\n",
    "           color='cornflowerblue', linewidth=3)\n",
    "ax[0].plot(y_hat.sum(axis=1).flatten(), label='Forecast',\n",
    "           color=\"#FAA01D\", linestyle='--', linewidth=3)\n",
    "ax[0].set_title('Actual vs. Forecast')\n",
    "ax[0].set_ylabel('Energy Consumption (kWh)')\n",
    "ax[0].legend()\n",
    "\n",
    "# Trend\n",
    "ax[1].plot(y_hat[0, 1]+y_hat[0, 0], color=\"#FAA01D\", linewidth=3)\n",
    "ax[1].set_title('Trend Decomposition')\n",
    "ax[1].set_ylabel('Energy Consumption (kWh)')\n",
    "\n",
    "# Seasonality\n",
    "ax[2].plot(y_hat[0, 2], color=\"#FAA01D\", linewidth=3)\n",
    "ax[2].set_title('Seasonality Decomposition')\n",
    "ax[2].set_ylabel('Energy Consumption (kWh)')\n",
    "ax[2].set_xlabel('Day of the Week')\n",
    "ax[2].set_xticks(np.arange(30))\n",
    "custom_labels = ['Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun',\n",
    "                 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun',\n",
    "                 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun',\n",
    "                 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun',\n",
    "                 'Mon', 'Tue', 'Wed']\n",
    "ax[2].set_xticklabels(custom_labels)\n",
    "ax[2].axvline(x=6, color='indianred', linestyle='--')\n",
    "ax[2].axvline(x=13, color='indianred', linestyle='--')\n",
    "ax[2].axvline(x=18, color='indianred', linestyle='--')\n",
    "ax[2].axvline(x=25, color='indianred', linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Long_Decomp.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Long_Decomp.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:70%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76129013",
   "metadata": {},
   "source": [
    "The model indicates that Kardo has an increasing trend from the start of the month until the middle of the month before it starts to decrease until the end. For the seasonality, the forecast shows less consumption from Saturday to Monday, which might indicate less activity in residence. \n",
    "\n",
    "Another thing to look at is the magnitude of the stacks' outputs and how it differs for the two forecast horizons. For the short-term forecast, the seasonality has a higher magnitude than the trend stack (subtracting the level prediction). While for long-term forecasts, the trend stack's output is higher in magnitude compared to the output of the seasonality stack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626f3ae",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#FAA01D; color:#F5F5F1; padding: 10px;\">Results and Discussion</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7faeb6",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Forecast Comparison</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd0805",
   "metadata": {},
   "source": [
    "In this section, we will compare the results of NBEATSx to other forecasting models. Also, we will use another explainability method, such as SHAP, to explain the effect of temperature on energy consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4d3c8",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/Short_MAPE_2.png\" width=\"60%\" height=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543dcd9a",
   "metadata": {},
   "source": [
    "In short-term forecasting, NBEATSx beats all other models, including seasonal naïve, random forest, and prophet, by having a MAPE of 4.59%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4810220d",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/Long_MAPE_2.png\" width=\"60%\" height=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0e191",
   "metadata": {},
   "source": [
    "In long-term forecasting, NBEATSx still beats all other models with a MAPE of 8.81%. As we increase the forecast horizon, it is expected that the accuracy of the forecasting model will drop. Compared to other models in this long-term forecast horizon, it is still one of the best.\n",
    "\n",
    "Stacking multiple blocks of fully connected layers while efficiently using backcasting and simple MLP allows NBEATSx to forecast more accurately. But the advantage of NBEATSx over other models is its ability to be interpretable, as demonstrated by earlier time series decomposition. Even though the MAPE differs slightly, this advantage makes NBEATSx a more desirable forecasting method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51aa45",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Other XAI (SHAP)</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28373e95",
   "metadata": {},
   "source": [
    "The results of random forest are interpreted using an explainability method called SHAP. SHAP or Shapley\n",
    "Additive exPlanations assign feature importance by quantifying the contribution of each\n",
    "feature to the model prediction. This provides insight into what features would clearly\n",
    "distinguish between the two classes. The global feature importance plot of the model is shown\n",
    "below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36199542",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/SHAP.png\" width=\"60%\" height=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343d3e2",
   "metadata": {},
   "source": [
    "The top feature in predicting energy consumption is temperature, humidity, and previous lag value. As the descriptive analysis corroborates, energy consumption decreases as temperature increases. We will explain a single forecast on our test set to further investigate this generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd4397",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/Waterfall.png\" width=\"60%\" height=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1e137",
   "metadata": {},
   "source": [
    "In this plot, we can see coming from the global average of energy consumption, the high-temperature value (relative to other time of the year) push the consumption towards lower energy consumption. Let us determine how big of a change in energy consumption each temperature increase.\n",
    "\n",
    "Here we calculated that for every one degrees Celsius increase in temperature, that is an equivalent 0.289 decrease in energy consumption (kWh)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43420760",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#FAA01D; color:#F5F5F1; padding: 10px;\">Key Takeaways</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e134bc",
   "metadata": {},
   "source": [
    "Deep Learning methods have proven to outperform classical statistical and machine learning methods in time series forecasting. However, accuracy alone is not the sole consideration. Explainability is equally important to establish trust with users. Fortunately, with NBEATSx, we can achieve both accuracy and explainability in our forecasts.\n",
    "\n",
    "NBEATSx provides faster and more efficient time series forecasting owing to its MLP-based architecture. In addition, it provides highly accurate forecasts. However, what really sets NBEATSx apart is its unique ability to decompose time series, revealing the underlying trends and seasonality that influence the forecasted values. This enhances the usability and practicality of the model, making it an attractive choice for time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c4a7d",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#FAA01D; color:#F5F5F1; padding: 10px;\">Github Link</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35a931",
   "metadata": {},
   "source": [
    "You may refer also to this github repo for the complete code and data: https://github.com/flippygarcia/msds2023_ml3_individual_project.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627cb3f5",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#FAA01D; color:#F5F5F1; padding: 10px;\">References</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b21912",
   "metadata": {},
   "source": [
    "[1] Tilford, A. (2023, Mar 30). *Apps to Help You Track Energy Use.* Retrieved June 18, 2023 from https://www.saveonenergy.com/resources/apps-track-energy-use/\n",
    "\n",
    "[2] Zheng, X. et al. (2022, Jun 22). *A multi-scale time-series dataset with benchmark for machine learning in decarbonized energy grids*. Retrieved June 18, 2023 from https://www.nature.com/articles/s41597-022-01455-7\n",
    "\n",
    "[3] Olivares, K. et al. (2023, Apr 04). *Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx.* Retrieved June 18, 2023 from https://arxiv.org/pdf/2104.05522.pdf\n",
    "\n",
    "[4] US Department of Commerce, N. (n.d.). *Discussion on Humidity*. Retrieved June 19, 2023 from Www.weather.gov. https://www.weather.gov/lmk/humidity#:~:text=Relative%20humidity%20(RH)%20(expressed,air%20at%20its%20current%20temperature.)\n",
    "\n",
    "[5] OpenAI. (2023). *ChatGPT* (May 24 version) [Large language model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69b2b1",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#FAA01D; color:#F5F5F1; padding: 10px;\">Appendix</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25cb4bf",
   "metadata": {},
   "source": [
    "In this section, the entire code used for the project is shown. This now includes the time series forecasting of random forest, and prophet. As well as XAI using SHAP and counterfactual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95c04b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Additional Exploratory Data Analysis</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef663ba3",
   "metadata": {},
   "source": [
    "An autocorrelation plot, or an ACF (Autocorrelation Function) plot, is a graphical tool used in time series analysis to identify any patterns or dependencies within the data. It shows the correlation between a time series and its lagged values. Statsmodel has a built-in function to produce an ACF plot given a time series dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b9db368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:04.595114Z",
     "start_time": "2023-06-19T14:28:04.553205Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d85b2f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:04.791039Z",
     "start_time": "2023-06-19T14:28:04.597198Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Auto_Cor.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Autocorrelation plot of energy consumption\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "plot_acf(df_eda[['energy_kWh']], zero=False, ax=ax)\n",
    "plt.title('Autocorrelation Plot of Energy Consumption',\n",
    "          fontsize=15, pad=20)\n",
    "plt.ylabel('Autocorrelation Values')\n",
    "plt.xlabel('Time Lag')\n",
    "plt.ylim(-0.2, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Auto_Cor.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Auto_Cor.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209be24",
   "metadata": {},
   "source": [
    "The ACF plot indicates a high correlation for all the lagged values from the first to the 30th. The peak correlation occurs at the first lagged values; the lowest is the 30th lagged value. For the trend, it has a seven-day cycle where the trend is decreasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd9b9a5",
   "metadata": {},
   "source": [
    "The succeeding plots are the histograms of the daily energy consumption and the exogenous variables. This can highlight the behavior of Kardo in terms of energy consumption and the environment he is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d236cab1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:05.053651Z",
     "start_time": "2023-06-19T14:28:04.793393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Histogram_Energy.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.histplot(df_eda[['energy_kWh']], x='energy_kWh', color='#cc5f16',\n",
    "             edgecolor='black', bins=50, legend=None,\n",
    "             kde=True)\n",
    "\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Energy(kWh)\")\n",
    "plt.title('Histogram of Energy Consumption of Residential Buildings',\n",
    "          fontsize=15, pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Histogram_Energy.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Histogram_Energy.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275dbc8",
   "metadata": {},
   "source": [
    "The histogram of the daily energy consumption shows that the energy consumption of Kardo is around 20-30 kWh. The peak energy consumption is around 50 kWh, and there are instances of below 10 kWh, which can result from power interruptions during that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b084066",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:05.315224Z",
     "start_time": "2023-06-19T14:28:05.055663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Histogram_Temp.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.histplot(df_eda[['temperature']], x='temperature', color='#321854',\n",
    "             edgecolor='black', bins=50, legend=None,\n",
    "             kde=True)\n",
    "\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Temperature(°C)\")\n",
    "plt.title('Histogram of Temperature of Residential Buildings',\n",
    "          fontsize=20, pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Histogram_Temp.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Histogram_Temp.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23951d26",
   "metadata": {},
   "source": [
    "The temperature histogram shows the variations in the weather in British Columbia, Canada. There are two peak counts, around 5 to 8 degrees Celsius and another at 15 to 19 degrees Celsius, due to the location having four seasons. The range of values is from -5 to around 25 degrees Celsius which extreme values have rare occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92378b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:05.565130Z",
     "start_time": "2023-06-19T14:28:05.317334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Histogram_Humidity.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.histplot(df_eda[['humidity']], x='humidity', color='#a81b64', bins=50, legend=None,\n",
    "             kde=True, palette='mako')\n",
    "\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Humidity (%)\")\n",
    "plt.title('Histogram of Humidity of Residential Buildings',\n",
    "          fontsize=20, pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Histogram_Humidity.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Histogram_Humidity.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a5d860",
   "metadata": {},
   "source": [
    "The humidity in British Columbia plays around 70% to 90% humidity during the time horizon of the dataset. The location has higher humidity levels due to its proximity to large bodies of water. There are extreme cases of being less than 60%, which means that air has a lower moisture content and can potentially be considered as dry or less humid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8674373c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:05.827628Z",
     "start_time": "2023-06-19T14:28:05.567395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Histogram_Pressure.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.histplot(df_eda[['pressure']], x='pressure', bins=50, legend=None,\n",
    "             color='red', kde=True)\n",
    "\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Pressure (kPa)\")\n",
    "plt.title('Histogram of Pressure of Residential Buildings',\n",
    "          fontsize=20, pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Histogram_Pressure.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Histogram_Pressure.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4860dd67",
   "metadata": {},
   "source": [
    "The histogram of the atmospheric pressure indicates that the usual pressure in the location of Kardo is around 101 to 102 kPa. This suggests that the location is most likely in lower terrain than high altitude areas. The variations in the pressure are connected to the changes in the area's temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66d79c",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Additional Time Series Forecasting</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6acb1aa",
   "metadata": {},
   "source": [
    "We used two other models to compare with the results NBEATSx: Random Forest and Prophet.\n",
    "\n",
    "Prophet is a time series forecasting model developed by Meta. Using an additive model, it handles trends, seasonality, and holidays in time series data. It has flexible trend modeling, handles various types of seasonality, incorporates holiday effects, and automatically detects change points. Prophet is user-friendly, scalable, and implemented in Python as an open-source library.\n",
    "\n",
    "Random Forest is a machine learning algorithm commonly used for time series analysis. It applies an ensemble of decision trees to make predictions based on features derived from historical time series data.\n",
    "\n",
    "The two models are compared to NBEATSx and the baseline Seasonal Naive mentioned in the post in both short-term and long-term forecast horizons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b501013a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:05.835125Z",
     "start_time": "2023-06-19T14:28:05.829706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataframe for Prophet\n",
    "df_prop = df_day.reset_index()\n",
    "df_prop = df_prop.rename(columns={'index': 'ds', 'energy_kWh': 'y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4e3df",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Short-Term (7-day ahead) Forecast</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "758abce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:06.035742Z",
     "start_time": "2023-06-19T14:28:05.837267Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prophet imports\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "from prophet import Prophet\n",
    "import logging\n",
    "logging.getLogger('prophet').setLevel(logging.WARNING)\n",
    "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e363856e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:07.163527Z",
     "start_time": "2023-06-19T14:28:06.038108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "prop_train = df_prop.iloc[:-hor_7]\n",
    "prop_test = df_prop.iloc[-hor_7:]\n",
    "\n",
    "# Forecast using Prophet\n",
    "m = Prophet(holidays=df_holiday)\n",
    "m.fit(prop_train)\n",
    "future = m.make_future_dataframe(periods=hor_7)\n",
    "forecast_7 = m.predict(future)\n",
    "\n",
    "# Save to dataframe\n",
    "df_prop_res_7 = (forecast_7[-hor_7:][['ds', 'yhat']]\n",
    "                 .set_index('ds').rename(columns={'yhat': 'Prophet'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "781ae38f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:07.215786Z",
     "start_time": "2023-06-19T14:28:07.165910Z"
    }
   },
   "outputs": [],
   "source": [
    "# ML imports\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (mean_absolute_error,\n",
    "                             mean_absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d328b87d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:28:07.267390Z",
     "start_time": "2023-06-19T14:28:07.218703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a features of shifted values\n",
    "ts_7 = pd.DataFrame()\n",
    "ts_7['y'] = df_all[['energy_kWh']]\n",
    "\n",
    "# Lookback window size\n",
    "window_size = hor_7 * 4\n",
    "\n",
    "# Create new columns of different lookback period\n",
    "for w in range(window_size):\n",
    "    ts_7['y_' + str(w + 1)] = df_all[['energy_kWh']].shift(w + 1)\n",
    "\n",
    "# Create x dataframe\n",
    "df_rf_7 = pd.concat([ts_7[window_size:], df_all[window_size:]], axis=1)\n",
    "df_x_7 = df_rf_7.drop(columns=['energy_kWh', 'y'])\n",
    "\n",
    "# Create y dataframe\n",
    "df_y_7 = pd.concat([df_all['energy_kWh'].shift(-i)\n",
    "                   for i in range(hor_7)], axis=1).dropna()\n",
    "df_y_7.columns = [f'y{i+1}' for i in range(hor_7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33c34a26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:32:32.291971Z",
     "start_time": "2023-06-19T14:28:07.269787Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.00s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.03s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.01s/it]\n",
      "100%|██████████| 12/12 [00:35<00:00,  2.97s/it]\n",
      "100%|██████████| 12/12 [00:35<00:00,  2.98s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize contrainer of predictions\n",
    "y_preds_rf = []\n",
    "\n",
    "# Define x_train/test\n",
    "x_train = df_x_7[:-hor_7].to_numpy()\n",
    "x_test = df_x_7[-hor_7:-hor_7+1].to_numpy()\n",
    "\n",
    "# Define y_train/test\n",
    "for col in df_y_7.columns:\n",
    "    y_train = df_y_7[[col]][hor_7*4:-1].to_numpy()\n",
    "    y_test = df_y_7[[col]][-1:].to_numpy()\n",
    "\n",
    "    # Fit Scaler on the training set\n",
    "    scaler_x = StandardScaler().fit(x_train)\n",
    "    scaler_y = StandardScaler().fit(y_train)\n",
    "\n",
    "    # Z-score normalization\n",
    "    x_train = scaler_x.transform(x_train)\n",
    "    y_train = scaler_y.transform(y_train)\n",
    "    x_test = scaler_x.transform(x_test)\n",
    "    y_test = scaler_y.transform(y_test)\n",
    "\n",
    "    # Results\n",
    "    df_mape_results = pd.DataFrame()\n",
    "    param_list = []\n",
    "    scores = []\n",
    "\n",
    "    # Param grid\n",
    "    n_estimators = [100, 200, 300]\n",
    "    max_depth = [3, 5, 10, 20]\n",
    "    grid = list(itertools.product(n_estimators, max_depth))\n",
    "\n",
    "    # Grid search\n",
    "    for param in tqdm(grid):\n",
    "        params = {\n",
    "            'n_estimators': param[0],\n",
    "            'max_depth': param[1],\n",
    "        }\n",
    "\n",
    "        model = RandomForestRegressor(**params, random_state=143)\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(x_train, y_train.ravel())\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred[..., np.newaxis])\n",
    "        y_true = scaler_y.inverse_transform(y_test)\n",
    "        y_true = y_test.copy()\n",
    "\n",
    "        # Store results\n",
    "        param_list.append(str(params))\n",
    "        scores.append(mean_absolute_percentage_error(y_true, y_pred))\n",
    "\n",
    "    # Compile results\n",
    "    df_mape_results['Params'] = param_list\n",
    "    df_mape_results['Scores'] = scores\n",
    "    df_mape_results.sort_values(by='Scores', inplace=True)\n",
    "\n",
    "    # Get model the best model\n",
    "    best_params = eval(df_mape_results.iloc[0, 0])\n",
    "    model = RandomForestRegressor(**best_params)\n",
    "    model.fit(x_train, y_train.ravel())\n",
    "    y_pred_rf = model.predict(x_test).flatten()\n",
    "    y_pred_rf = scaler_y.inverse_transform(y_pred_rf[..., np.newaxis])\n",
    "    y_preds_rf.append(y_pred_rf[0][0])\n",
    "\n",
    "# Create dataframe of results\n",
    "df_rf_res_7 = pd.DataFrame(y_preds_rf,\n",
    "                           index=df_snaive_7.index, columns=['Random_Forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b887e49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:32:32.314844Z",
     "start_time": "2023-06-19T14:32:32.295919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seasonal_Naive</td>\n",
       "      <td>3.041286</td>\n",
       "      <td>0.112502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>2.216157</td>\n",
       "      <td>0.079194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prophet</td>\n",
       "      <td>1.365396</td>\n",
       "      <td>0.052350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBEATSx</td>\n",
       "      <td>1.247066</td>\n",
       "      <td>0.045908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model       MAE      MAPE\n",
       "0  Seasonal_Naive  3.041286  0.112502\n",
       "1   Random_Forest  2.216157  0.079194\n",
       "2         Prophet  1.365396  0.052350\n",
       "3         NBEATSx  1.247066  0.045908"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine all predictions and actual\n",
    "df_predict_7 = df_day.copy()\n",
    "df_predict_7 = df_predict_7.rename(columns={'energy_kWh': 'Actual'})\n",
    "df_predict_7 = df_predict_7[-hor_7:]\n",
    "df_predict_7 = pd.concat([df_predict_7, df_snaive_7, df_rf_res_7,\n",
    "                          df_prop_res_7, df_nbtx_res_7], axis=1)\n",
    "\n",
    "# Append the model score to the results dataframe\n",
    "model_ls = []\n",
    "mae_ls = []\n",
    "mape_ls = []\n",
    "for col in df_predict_7.columns[1:]:\n",
    "    model_ls.append(col)\n",
    "    mae_ls.append(mean_absolute_error(df_predict_7['Actual'],\n",
    "                                      df_predict_7[col]))\n",
    "    mape_ls.append(mean_absolute_percentage_error(df_predict_7['Actual'],\n",
    "                                                  df_predict_7[col]))\n",
    "\n",
    "df_results_7 = pd.DataFrame(\n",
    "    {'Model': model_ls, 'MAE': mae_ls, 'MAPE': mape_ls})\n",
    "display(df_results_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c54de5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:32:32.447268Z",
     "start_time": "2023-06-19T14:32:32.317067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Short_MAPE_2.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:60%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Results of Different Models\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.barh(df_results_7['Model'], df_results_7['MAPE'], color='#FAA01D')\n",
    "ax.set_title('MAPE Comparison of Different Models')\n",
    "ax.set_xlabel('Mean Absolute Percentage Error')\n",
    "ax.set_yticklabels(['Seasonal Naive', 'Random Forest', 'Prophet', 'NBEATSx'])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Short_MAPE_2.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Short_MAPE_2.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:60%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf6cad",
   "metadata": {},
   "source": [
    "In short-term forecasting, NBEATSx beats all other models, including seasonal naïve, random forest, and prophet, by having a MAPE of 4.59%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dd7a6dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:32:32.713064Z",
     "start_time": "2023-06-19T14:32:32.449367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Short_Prediction_2.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time Series Prediction\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(df_predict_7.index, df_predict_7['Actual'],\n",
    "        label='Actual', color='cornflowerblue', linewidth=3)\n",
    "ax.plot(df_predict_7.index, df_predict_7['Random_Forest'],\n",
    "        label='Random Forest', linestyle='--', color='indianred', linewidth=3)\n",
    "ax.plot(df_predict_7.index, df_predict_7['Prophet'],\n",
    "        label='Prophet', linestyle='--', color='#FAA01D', linewidth=3)\n",
    "ax.set_title('Actual vs. Random Forest & Prophet Short-Term Prediction')\n",
    "ax.set_ylabel('Daily Energy Consumption (kWh)')\n",
    "ax.set_xlabel('Test Prediction Dates')\n",
    "ax.legend()\n",
    "ax.set_ylim(20, 35)\n",
    "ax.tick_params(axis='x', rotation=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Short_Prediction_2.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Short_Prediction_2.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c8835f",
   "metadata": {},
   "source": [
    "One noticeable difference between the two forecasts is that prophet predicts higher values than the random forest. Another observation is that rise and fall in the prediction behavior of the prophet better mimics those of the actual values. This might be why the prophet has a lower MAPE between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161111f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#808080\">Long-Term (30-day ahead) Forecast</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9effabaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:32:33.688034Z",
     "start_time": "2023-06-19T14:32:32.715412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "prop_train = df_prop.iloc[:-hor_30]\n",
    "prop_test = df_prop.iloc[-hor_30:]\n",
    "\n",
    "# Forecast using Prophet\n",
    "m = Prophet(holidays=df_holiday)\n",
    "m.fit(prop_train)\n",
    "future = m.make_future_dataframe(periods=hor_30)\n",
    "forecast_30 = m.predict(future)\n",
    "\n",
    "# Save to dataframe\n",
    "df_prop_res_30 = (forecast_30[-hor_30:][['ds', 'yhat']]\n",
    "                  .set_index('ds').rename(columns={'yhat': 'Prophet'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d6a3058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:32:33.761420Z",
     "start_time": "2023-06-19T14:32:33.693984Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a features of shifted values\n",
    "ts_30 = pd.DataFrame()\n",
    "ts_30['y'] = df_all[['energy_kWh']]\n",
    "\n",
    "# Lookback window size\n",
    "window_size = hor_30\n",
    "\n",
    "# Create new columns of different lookback period\n",
    "for w in range(window_size):\n",
    "    ts_30['y_' + str(w + 1)] = df_all[['energy_kWh']].shift(w + 1)\n",
    "\n",
    "# Create x dataframe\n",
    "df_rf_30 = pd.concat([ts_30[window_size:], df_all[window_size:]], axis=1)\n",
    "df_x_30 = df_rf_30.drop(columns=['energy_kWh', 'y'])\n",
    "\n",
    "# Create y dataframe\n",
    "df_y_30 = pd.concat([df_all['energy_kWh'].shift(-i) for i in range(hor_30)],\n",
    "                    axis=1).dropna()\n",
    "df_y_30.columns = [f'y{i+1}' for i in range(hor_30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be87704a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:52:01.883719Z",
     "start_time": "2023-06-19T14:32:33.764097Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:36<00:00,  3.08s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.14s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.12s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.08s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.07s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.09s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.14s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.09s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.08s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.12s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.07s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.07s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.06s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.07s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.08s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.07s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.08s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.09s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.12s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.08s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.15s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.09s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.13s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.08s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.12s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.08s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.10s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.14s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.14s/it]\n",
      "100%|██████████| 12/12 [00:37<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize contrainer of predictions\n",
    "y_preds_rf = []\n",
    "\n",
    "# Define x_train/test\n",
    "x_train = df_x_30[:-hor_30].to_numpy()\n",
    "x_test = df_x_30[-hor_30:-hor_30+1].to_numpy()\n",
    "\n",
    "# Define y_train/test\n",
    "for col in df_y_30.columns:\n",
    "    y_train = df_y_30[[col]][hor_30:-1].to_numpy()\n",
    "    y_test = df_y_30[[col]][-1:].to_numpy()\n",
    "\n",
    "    # Fit Scaler on the training set\n",
    "    scaler_x = StandardScaler().fit(x_train)\n",
    "    scaler_y = StandardScaler().fit(y_train)\n",
    "\n",
    "    # Z-score normalization\n",
    "    x_train = scaler_x.transform(x_train)\n",
    "    y_train = scaler_y.transform(y_train)\n",
    "    x_test = scaler_x.transform(x_test)\n",
    "    y_test = scaler_y.transform(y_test)\n",
    "\n",
    "    # Results\n",
    "    df_mape_results = pd.DataFrame()\n",
    "    param_list = []\n",
    "    scores = []\n",
    "\n",
    "    # Param grid\n",
    "    n_estimators = [100, 200, 300]\n",
    "    max_depth = [3, 5, 10, 20]\n",
    "    grid = list(itertools.product(n_estimators, max_depth))\n",
    "\n",
    "    # Grid search\n",
    "    for param in tqdm(grid):\n",
    "        params = {\n",
    "            'n_estimators': param[0],\n",
    "            'max_depth': param[1],\n",
    "        }\n",
    "\n",
    "        model = RandomForestRegressor(**params, random_state=143)\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(x_train, y_train.ravel())\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred[..., np.newaxis])\n",
    "        y_true = scaler_y.inverse_transform(y_test)\n",
    "        y_true = y_test.copy()\n",
    "\n",
    "        # Store results\n",
    "        param_list.append(str(params))\n",
    "        scores.append(mean_absolute_percentage_error(y_true, y_pred))\n",
    "\n",
    "    # Compile results\n",
    "    df_mape_results['Params'] = param_list\n",
    "    df_mape_results['Scores'] = scores\n",
    "    df_mape_results.sort_values(by='Scores', inplace=True)\n",
    "\n",
    "    # Get model the best model\n",
    "    best_params = eval(df_mape_results.iloc[0, 0])\n",
    "    model = RandomForestRegressor(**best_params)\n",
    "    model.fit(x_train, y_train.ravel())\n",
    "    y_pred_rf = model.predict(x_test).flatten()\n",
    "    y_pred_rf = scaler_y.inverse_transform(y_pred_rf[..., np.newaxis])\n",
    "    y_preds_rf.append(y_pred_rf[0][0])\n",
    "\n",
    "# Create dataframe of results\n",
    "df_rf_res_30 = pd.DataFrame(y_preds_rf,\n",
    "                            index=df_snaive_30.index,\n",
    "                            columns=['Random_Forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25cc25ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:52:01.906208Z",
     "start_time": "2023-06-19T14:52:01.886646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seasonal_Naive</td>\n",
       "      <td>4.499367</td>\n",
       "      <td>0.159477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>3.430852</td>\n",
       "      <td>0.112313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prophet</td>\n",
       "      <td>2.754180</td>\n",
       "      <td>0.090177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBEATSx</td>\n",
       "      <td>2.562424</td>\n",
       "      <td>0.088149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model       MAE      MAPE\n",
       "0  Seasonal_Naive  4.499367  0.159477\n",
       "1   Random_Forest  3.430852  0.112313\n",
       "2         Prophet  2.754180  0.090177\n",
       "3         NBEATSx  2.562424  0.088149"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine all predictions and actual\n",
    "df_predict_30 = df_day.copy()\n",
    "df_predict_30 = df_predict_30.rename(columns={'energy_kWh': 'Actual'})\n",
    "df_predict_30 = df_predict_30[-hor_30:]\n",
    "df_predict_30 = pd.concat([df_predict_30, df_snaive_30, df_rf_res_30,\n",
    "                           df_prop_res_30, df_nbtx_res_30], axis=1)\n",
    "\n",
    "# Append the model score to the results dataframe\n",
    "model_ls = []\n",
    "mae_ls = []\n",
    "mape_ls = []\n",
    "for col in df_predict_30.columns[1:]:\n",
    "    model_ls.append(col)\n",
    "    mae_ls.append(mean_absolute_error(df_predict_30['Actual'],\n",
    "                                      df_predict_30[col]))\n",
    "    mape_ls.append(mean_absolute_percentage_error(df_predict_30['Actual'],\n",
    "                                                  df_predict_30[col]))\n",
    "\n",
    "df_results_30 = pd.DataFrame(\n",
    "    {'Model': model_ls, 'MAE': mae_ls, 'MAPE': mape_ls})\n",
    "display(df_results_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "915a5901",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:52:02.147243Z",
     "start_time": "2023-06-19T14:52:01.908555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Long_MAPE_2.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:60%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Results of Different Models\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.barh(df_results_30['Model'], df_results_30['MAPE'], color='#FAA01D')\n",
    "ax.set_title('MAPE Comparison of Different Models')\n",
    "ax.set_xlabel('Mean Absolute Percentage Error')\n",
    "ax.set_yticklabels(['Seasonal Naive', 'Random Forest', 'Prophet', 'NBEATSx'])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Long_MAPE_2.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Long_MAPE_2.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:60%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144d4ff",
   "metadata": {},
   "source": [
    "In long-term forecasting, NBEATSx still beats all other models with a MAPE of 8.81%. As we increase the forecast horizon, it is expected that the accuracy of the forecasting model will drop. Compared to other models in this long-term forecast horizon, it is still one of the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c711de59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:52:02.459720Z",
     "start_time": "2023-06-19T14:52:02.150031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Long_Prediction_2.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time Series Prediction\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(df_predict_30.index, df_predict_30['Actual'],\n",
    "        label='Actual', color='cornflowerblue', linewidth=3)\n",
    "ax.plot(df_predict_30.index, df_predict_30['Random_Forest'],\n",
    "        label='Random Forest', linestyle='--', color='indianred', linewidth=3)\n",
    "ax.plot(df_predict_30.index, df_predict_30['Prophet'],\n",
    "        label='Prophet', linestyle='--', color='#FAA01D', linewidth=3)\n",
    "ax.set_title('Actual vs. Random Forest & Prophet Long-Term Prediction')\n",
    "ax.set_ylabel('Daily Energy Consumption (kWh)')\n",
    "ax.set_xlabel('Test Prediction Dates')\n",
    "ax.legend()\n",
    "ax.set_ylim(20, 40)\n",
    "ax.tick_params(axis='x', rotation=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig(\"./images/Long_Prediction_2.png\")\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Long_Prediction_2.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a7e7d",
   "metadata": {},
   "source": [
    "Compared to the short-term forecast, the prediction of random forest and prophet now intersects. But still, prophets closely follow the up and down of those of the actual value, making it have lower MAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1ce56",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFC40F\">Additional XAI</h2>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8246d",
   "metadata": {},
   "source": [
    "The code for SHAP mentioned in the main body is indicated below. Random Forest was the model used when applying SHAP to provide explainability. To further provide the value of an explainability model such as SHAP, we contextualize the results by showing how much energy consumption changes when the temperature increases or decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e9087e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:52:03.038786Z",
     "start_time": "2023-06-19T14:52:02.462150Z"
    }
   },
   "outputs": [],
   "source": [
    "# XAI imports\n",
    "import shap\n",
    "from dice_ml import Model, Dice, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6fd9e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:52:03.046286Z",
     "start_time": "2023-06-19T14:52:03.041515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set horizon for XAI\n",
    "horizon = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b421dfe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:52:03.070599Z",
     "start_time": "2023-06-19T14:52:03.049053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a features of shifted values\n",
    "ts = pd.DataFrame()\n",
    "ts['y'] = df_all[['energy_kWh']]\n",
    "\n",
    "# Lookback window size\n",
    "window_size = 7\n",
    "\n",
    "# Create new columns of different lookback period\n",
    "for w in range(window_size):\n",
    "    ts['y_' + str(w + 1)] = df_all[['energy_kWh']].shift(w + 1)\n",
    "\n",
    "# Adjust dataframe to remove NaN\n",
    "df_rf = pd.concat([ts[window_size:], df_all[window_size:]], axis=1)\n",
    "df_rf = df_rf.drop(columns=['energy_kWh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a57b1d60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:52:18.515275Z",
     "start_time": "2023-06-19T14:52:03.073322Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:14<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train-Test split\n",
    "df_rf_train = df_rf[:-horizon]\n",
    "df_rf_test = df_rf[-horizon:]\n",
    "x_train = df_rf_train.drop(['y'], axis=1)\n",
    "y_train = df_rf_train[['y']]\n",
    "x_test = df_rf_test.drop(['y'], axis=1)\n",
    "y_test = df_rf_test[['y']]\n",
    "\n",
    "# Results\n",
    "df_mae_results = pd.DataFrame()\n",
    "param_list = []\n",
    "scores = []\n",
    "\n",
    "# Param grid\n",
    "n_estimators = [100, 200, 300]\n",
    "max_depth = [3, 5, 10, 20]\n",
    "grid = list(itertools.product(n_estimators, max_depth))\n",
    "\n",
    "# 1 day ahead forecasting\n",
    "for param in tqdm(grid):\n",
    "    params = {\n",
    "        'n_estimators': param[0],\n",
    "        'max_depth': param[1],\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**params, random_state=143)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_true = y_test.copy()\n",
    "\n",
    "    # Store results\n",
    "    param_list.append(str(params))\n",
    "    scores.append(mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "# Compile results\n",
    "df_mae_results['Params'] = param_list\n",
    "df_mae_results['Scores'] = scores\n",
    "df_mae_results.sort_values(by='Scores', inplace=True)\n",
    "\n",
    "# Get model the best model\n",
    "best_params = eval(df_mae_results.iloc[0, 0])\n",
    "model = RandomForestRegressor(**best_params)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_rf = model.predict(x_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0220a845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:54:20.307528Z",
     "start_time": "2023-06-19T14:52:18.517683Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 121it [02:01,  1.08s/it]                         \n"
     ]
    }
   ],
   "source": [
    "shap_explainer = shap.Explainer(\n",
    "    model.predict, x_test, feature_names=x_test.columns)\n",
    "shap_values = shap_explainer(x_test.iloc[:, :])\n",
    "shap_explanation = shap.Explanation(shap_values.values[:, :],\n",
    "                                    shap_values.base_values[0],\n",
    "                                    shap_values.data,\n",
    "                                    feature_names=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85826d7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:54:20.317517Z",
     "start_time": "2023-06-19T14:54:20.310380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/SHAP.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Global feature importance\n",
    "# shap.summary_plot(shap_explanation, plot_type='bar', plot_size=(14, 10))\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/SHAP.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85bc51",
   "metadata": {},
   "source": [
    "The top feature in predicting energy consumption is temperature, humidity, and previous lag value. As the descriptive analysis corroborates, energy consumption decreases as temperature increases. We will explain a single forecast on our test set to further investigate this generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a9e8160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:54:20.330574Z",
     "start_time": "2023-06-19T14:54:20.322704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./images/Waterfall.png\" alt=\"plots\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Waterfall diagram\n",
    "# shap.plots.waterfall(shap_explanation[4])\n",
    "\n",
    "# Create an HTML img tag to display the image\n",
    "img_tag = (f'<img src=\"./images/Waterfall.png\" alt=\"plots\" style='\n",
    "           '\"display:block;margin-left:auto;margin-right:auto;width:80%;\">')\n",
    "\n",
    "# Display the img tag in the Jupyter Notebook\n",
    "display(HTML(img_tag))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6bf72",
   "metadata": {},
   "source": [
    "In this plot, we can see coming from the global average of energy consumption, the high-temperature value (relative to other time of the year) push the consumption towards lower energy consumption. Let us determine how big of a change in energy consumption each temperature increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68d133d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:54:20.364526Z",
     "start_time": "2023-06-19T14:54:20.333750Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = Model(model=model, backend='sklearn', model_type='regressor')\n",
    "dice_data = Data(\n",
    "    dataframe=df_rf_test,\n",
    "    continuous_features=['y_1', 'y_2', 'y_3', 'y_4', 'y_5', 'y_6', 'y_7',\n",
    "                         'temperature', 'humidity', 'pressure'],\n",
    "    outcome_name='y'\n",
    ")\n",
    "dice_exp = Dice(dice_data, model1, method='genetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee55d586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:54:20.370975Z",
     "start_time": "2023-06-19T14:54:20.366656Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rf_test_x = df_rf_test.drop(columns='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74fde364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:55:24.713093Z",
     "start_time": "2023-06-19T14:54:20.373284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.54s/it]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.85s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.58s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.49s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.53s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.47s/it]\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.56s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.43s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.15s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.56s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "power_deltas = []\n",
    "for i in range(1, 16):\n",
    "    np.random.seed(630)\n",
    "    cfes1 = dice_exp.generate_counterfactuals(\n",
    "        df_rf_test_x.iloc[[i]],\n",
    "        total_CFs=1,\n",
    "        desired_range=[25, 26],\n",
    "        features_to_vary=['temperature'])\n",
    "    new_power = dice_exp.final_cfs_df['y'][0]\n",
    "    new_temp = dice_exp.final_cfs_df['temperature'][0]\n",
    "    old_power = model.predict(df_rf_test_x.iloc[[i]])[0]\n",
    "    old_temp = df_rf_test_x.iloc[[i]]['temperature'][0]\n",
    "    power_delta = ((new_power - old_power) / (new_temp - old_temp))\n",
    "    power_deltas.append(power_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33d65171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T14:55:24.719971Z",
     "start_time": "2023-06-19T14:55:24.715322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.289 kWh change in energy consumption change for every 1 degree Celcius increase in temperature\n"
     ]
    }
   ],
   "source": [
    "print(f'{np.mean(power_deltas):.3f} kWh change in energy consumption change for every 1 degree '\n",
    "      'Celcius increase in temperature')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
